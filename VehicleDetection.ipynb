{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpath = glob.glob('./vehicles/*/*.png')\n",
    "imv=[]\n",
    "for i in vpath:\n",
    "    im=cv2.imread(i)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    imv.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvpath = glob.glob('./non-vehicles/*/*.png')\n",
    "imnv=[]\n",
    "for i in nvpath:\n",
    "    im=cv2.imread(i)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    imnv.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hogfeatures(image,orient,cellsPerBlock,pixelsPerCell, feature_vector_flag=True):\n",
    "    hog_features = hog(image, orientations=orient,\n",
    "        pixels_per_cell=(pixelsPerCell, pixelsPerCell), \n",
    "        cells_per_block=(cellsPerBlock, cellsPerBlock), \n",
    "        visualise=False, feature_vector=feature_vector_flag)\n",
    "    return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(images,orientation,cellsPerBlock,pixelsPerCell, convertColorspace=False):\n",
    "    featureList=[]\n",
    "    imageList=[]\n",
    "    for image in images:\n",
    "        if(convertColorspace==True):\n",
    "            image= cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        local_features_1=hogfeatures(image[:,:,0],orientation,cellsPerBlock,pixelsPerCell,  True)\n",
    "        local_features_2=hogfeatures(image[:,:,1],orientation,cellsPerBlock,pixelsPerCell,  True)\n",
    "        local_features_3=hogfeatures(image[:,:,2],orientation,cellsPerBlock,pixelsPerCell,  True)\n",
    "        x=np.hstack((local_features_1,local_features_2,local_features_3))\n",
    "        featureList.append(x)\n",
    "    return featureList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skimage/feature/_hog.py:239: skimage_deprecation: Argument `visualise` is deprecated and will be changed to `visualize` in v0.16\n",
      "  'be changed to `visualize` in v0.16', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "orientations=9\n",
    "cellsPerBlock=2\n",
    "pixelsPerBlock=16\n",
    "convertColorSpace=True\n",
    "vehicleFeatures= features(imv,orientations,cellsPerBlock,pixelsPerBlock, convertColorSpace)\n",
    "nonVehicleFeatures= features(imnv,orientations,cellsPerBlock,pixelsPerBlock, convertColorSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresList= np.vstack([vehicleFeatures, nonVehicleFeatures])\n",
    "labelList= np.concatenate([np.ones(len(vehicleFeatures)), np.zeros(len(nonVehicleFeatures))])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,  X_test,Y_train, Y_test = train_test_split(featuresList, labelList, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8792"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vehicleFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler= StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled= scaler.transform(X_train)\n",
    "X_test_scaled= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier1= LinearSVC()\n",
    "classifier1.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    imcopy = np.copy(img)\n",
    "    for bbox in bboxes:\n",
    "        r=random.randint(0,255)\n",
    "        g=random.randint(0,255)\n",
    "        b=random.randint(0,255)\n",
    "        color=(r, g, b)\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.9, 0.9)):\n",
    "   \n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0]=0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1]=img.shape[1]\n",
    "    if y_start_stop[0] ==  None:\n",
    "        y_start_stop[0]= 0\n",
    "    if y_start_stop[1] ==  None:\n",
    "        y_start_stop[1]=img.shape[0]\n",
    "    \n",
    "    \n",
    "    window_list = []\n",
    "    image_width_x= x_start_stop[1] - x_start_stop[0]\n",
    "    image_width_y= y_start_stop[1] - y_start_stop[0]\n",
    "     \n",
    "    windows_x = np.int( 1 + (image_width_x - xy_window[0])/(xy_window[0] * xy_overlap[0]))\n",
    "    windows_y = np.int( 1 + (image_width_y - xy_window[1])/(xy_window[1] * xy_overlap[1]))\n",
    "    \n",
    "    modified_window_size= xy_window\n",
    "    for i in range(0,windows_y):\n",
    "        y_start = y_start_stop[0] + np.int( i * modified_window_size[1] * xy_overlap[1])\n",
    "        for j in range(0,windows_x):\n",
    "            x_start = x_start_stop[0] + np.int( j * modified_window_size[0] * xy_overlap[0])\n",
    "            \n",
    "            x1 = np.int( x_start +  modified_window_size[0])\n",
    "            y1= np.int( y_start + modified_window_size[1])\n",
    "            window_list.append(((x_start,y_start),(x1,y1)))\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawCarsOptimised(image, image1, image2,windows, converColorspace=False):\n",
    "    refinedWindows=[]\n",
    "    for window in windows:\n",
    "        \n",
    "        start= window[0]\n",
    "        end= window[1]\n",
    "        clippedImage=image[start[1]:end[1], start[0]:end[0]]\n",
    "        clippedImage1=image1[start[1]:end[1], start[0]:end[0]]\n",
    "        clippedImage2=image2[start[1]:end[1], start[0]:end[0]]\n",
    "        \n",
    "        if(clippedImage.shape[1] == clippedImage.shape[0] and clippedImage.shape[1]!=0):\n",
    "            \n",
    "            clippedImage=cv2.resize(clippedImage, (64,64)).ravel()\n",
    "            clippedImage1=cv2.resize(clippedImage1, (64,64)).ravel()\n",
    "            clippedImage2=cv2.resize(clippedImage2, (64,64)).ravel()\n",
    "            \n",
    "            #f1=ExtractFeatures([clippedImage], 9 , 2 , 16,converColorspace)\n",
    "            f1= np.hstack((clippedImage,clippedImage1,clippedImage2))\n",
    "            f1=scaler.transform(f1.reshape(1,-1))   \n",
    "            print(f1.shape)\n",
    "            predictedOutput=classifier1.predict([f1[0]])\n",
    "            if(predictedOutput==1):\n",
    "                refinedWindows.append(window)\n",
    "        \n",
    "    return refinedWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
